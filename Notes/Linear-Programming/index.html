<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Welcome to Hongyi Li's website</title><meta name="author" content="Hongyi Li"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Welcome to Hongyi Li's website" type="application/atom+xml">
<!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Welcome to Hongyi Li's website</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/About"> About</a></li><li class="menus_item"><a class="site-page" href="/Research"> Research</a></li><li class="menus_item"><a class="site-page" href="/Project"> Project</a></li><li class="menus_item"><a class="site-page" href="/Notes"> Notes</a></li><li class="menus_item"><a class="site-page" href="/Album"> Album</a></li><li class="menus_item"><a class="site-page" href="/Feiyue"> Feiyue for ECE</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/HYLI.png" onerror="this.onerror=null;this.src='/img/HYLI.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Hongyi Li</h3><p class="author-bio">I am a Ph.D. student in electrical engineering at University of Macau. I received the B.Eng. degree from Huazhong University of Science and Technology in 2020, and the M.Sc. degree from Imperial College London in 2021, both in electrical engineering.</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://github.com/LHYi/" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/img/wx.png" target="_blank"><i class="fab fa-weixin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/img/tim.png" target="_blank"><i class="fab fa-qq" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto:hongyi.li@connect.um.edu.mo#E-mail" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="/img/googlescholar.html" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li></ul></div><a class="cv-links" href="/attaches/Hongyi_CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>Detailed CV (English Version)</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">Linear Programming</h2><article><p>I am learning the book “Optimization Models” recently and I see a blogger recommends Prof. Shu-Cheng Fang’s course “Linear Programming” as a supplement. The OCW <a href="https://www.bilibili.com/video/BV1A5411r7TK?p=1" target="_blank" rel="noopener">course video</a> is found in Bilibili.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- TOC -->
<ul>
<li><a href="#lecture-0---lecture-2-introduction-perliminaries">Lecture 0 - Lecture 2: Introduction, Perliminaries</a><ul>
<li><a href="#standard-form-of-lp-model">Standard Form of LP Model</a><ul>
<li><a href="#explicit-form">Explicit Form</a></li>
<li><a href="#matrix-form">Matrix Form</a></li>
</ul>
</li>
<li><a href="#embedded-assumptions-in-lp">Embedded Assumptions in LP</a></li>
<li><a href="#converting-to-standard-lp">Converting to Standard LP</a><ul>
<li><a href="#rule-1-unrestricted-free-variables">Rule 1: Unrestricted (free) variables</a></li>
<li><a href="#rule-2-inequality-constraints">Rule 2: Inequality constraints</a></li>
<li><a href="#rule-3-minimization-of-the-objective-funtion">Rule 3: Minimization of the Objective Funtion</a></li>
</ul>
</li>
<li><a href="#potential-problem-caused-by-standardizing">Potential Problem caused by Standardizing</a></li>
</ul>
</li>
<li><a href="#lecture-3-geometry-of-lp">Lecture 3: Geometry of LP</a><ul>
<li><a href="#terminologies">Terminologies</a><ul>
<li><a href="#baseline-model">Baseline model:</a></li>
<li><a href="#feasible-domain">Feasible domain</a></li>
<li><a href="#feasible-solution">Feasible solution</a></li>
<li><a href="#consistency">Consistency</a></li>
</ul>
</li>
<li><a href="#background-knowledge">Background knowledge</a><ul>
<li><a href="#definition-of-hyperplane">Definition of hyperplane</a></li>
<li><a href="#properties-of-hyperplanes">Properties of hyperplanes</a></li>
<li><a href="#properties-of-feasible-solution-set">Properties of feasible solution set</a></li>
<li><a href="#properties-of-optimal-solutions">Properties of optimal solutions</a></li>
</ul>
</li>
<li><a href="#graphic-method">Graphic method</a><ul>
<li><a href="#step-1">Step 1:</a></li>
<li><a href="#step-2">Step 2:</a></li>
</ul>
</li>
<li><a href="#fundamental-theorem-of-lp">Fundamental theorem of LP</a><ul>
<li><a href="#background-knowledge-1">Background knowledge</a></li>
</ul>
</li>
<li><a href="#the-geometric-meaning-of-the-feasible-domain">The geometric meaning of the feasible domain</a><ul>
<li><a href="#interior-and-boundary-points">Interior and boundary points</a></li>
<li><a href="#how-to-define-a-convex-set-s">How to define a convex set <strong>S</strong></a></li>
<li><a href="#difference-among-boundary-points">Difference among boundary points</a></li>
<li><a href="#finding-extreme-points">Finding extreme points</a></li>
<li><a href="#managing-extreme-points-algebraically">Managing extreme points algebraically</a></li>
<li><a href="#what-do-extreme-points-bring-us">What do extreme points bring us?</a></li>
<li><a href="#resolution-theorem">Resolution theorem</a></li>
<li><a href="#fundamental-theorem-of-lp-1">Fundamental theorem of LP</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#lecture-4-simplex-method">Lecture 4: Simplex Method</a><ul>
<li><a href="#basic-idea">Basic Idea:</a></li>
<li><a href="#nondegeneracy">Nondegeneracy</a><ul>
<li><a href="#property-1">Property 1:</a></li>
<li><a href="#property-2">Property 2:</a></li>
</ul>
</li>
<li><a href="#simplex-method-under-nondegeneracy">Simplex method under nondegeneracy</a><ul>
<li><a href="#basic-idea-1">Basic idea:</a></li>
<li><a href="#definition">Definition</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC -->
<hr>
<h2 id="Lecture-0-Lecture-2-Introduction-Perliminaries"><a href="#Lecture-0-Lecture-2-Introduction-Perliminaries" class="headerlink" title="Lecture 0 - Lecture 2: Introduction, Perliminaries"></a>Lecture 0 - Lecture 2: Introduction, Perliminaries</h2><p>In linear programming (LP), we established a LP model to solve a realistic problem (in approximate way). To establish the LP model, the steps is as followed:</p>
<ol>
<li>What are the variables to be involved? (This is the first thing we should think about)</li>
<li>What’s the objective function?</li>
<li>How are the variables constrained? (The order of step 2 and 3 is not fixed, since they are independent)</li>
</ol>
<h3 id="Standard-Form-of-LP-Model"><a href="#Standard-Form-of-LP-Model" class="headerlink" title="Standard Form of LP Model"></a>Standard Form of LP Model</h3><p>Including:</p>
<ul>
<li>n variables</li>
<li>1 objective function</li>
<li>m constraints</li>
<li>non-negative variables</li>
</ul>
<h4 id="Explicit-Form"><a href="#Explicit-Form" class="headerlink" title="Explicit Form"></a>Explicit Form</h4><script type="math/tex; mode=display">
\begin{aligned}
    & \text{Minimize} &\;\bold{z}=c_1x_1+c_2x_2+\cdots+c_nx_n\\
    & \text{subject to} &\\
    & & a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n=b_1\\
    & & a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n=b_2\\
    & & \vdots\\
    & & a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n=b_m\\
    & & x_1\geq0,\;x_2\geq0,\;,\cdots,\;x_n\geq0
\end{aligned}</script><ul>
<li>Minimizing one objective function.</li>
<li>Equality constrains.</li>
<li>Non-negative variables.</li>
</ul>
<h4 id="Matrix-Form"><a href="#Matrix-Form" class="headerlink" title="Matrix Form"></a>Matrix Form</h4><script type="math/tex; mode=display">
\begin{aligned}
    && \text{Min} \; \bold{c}^T\bold{x}\\
    && \text{s.t.} \; \bold{AX}=\bold{b}\\
    && \bold{x}\geq0
\end{aligned}</script><p>in which, $\bold{c}=\left[\begin{array}{c}c<em>1\c_2\\vdots\c_n\end{array}\right]$ is the cost vector, $\bold{x}=\left[\begin{array}{c}x_1\x_2\\vdots\x_n\end{array}\right]$ is the solution vector, $\bold{b}=\left[\begin{array}{c}b_1\b_2\\vdots\b_n\end{array}\right]$ is the right-hand-side vector and $\bold{A}=\left[\begin{array}{cccc}a</em>{11}&amp;a<em>{12}&amp;\cdots&amp;a</em>{1n}\a<em>{21}&amp;a</em>{22}&amp;\cdots&amp;a<em>{12n}\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\a</em>{n1}&amp;a<em>{n2}&amp;\cdots&amp;a</em>{nn}\\end{array}\right]$is the constrain matrix.</p>
<h3 id="Embedded-Assumptions-in-LP"><a href="#Embedded-Assumptions-in-LP" class="headerlink" title="Embedded Assumptions in LP"></a>Embedded Assumptions in LP</h3><ol>
<li><p>Proportionality Assumption</p>
<ul>
<li>No discount</li>
<li>No economy of return to scale</li>
</ul>
</li>
<li><p>Additivity Assumption</p>
<ul>
<li>Total contribution = Sum of contributions of individual variables</li>
</ul>
</li>
<li><p>Divisibility Assumption</p>
<ul>
<li>Any fractional value is allowed</li>
</ul>
</li>
<li><p>Certainty Assumption</p>
<ul>
<li>Each parameter is know for sure</li>
</ul>
</li>
</ol>
<h3 id="Converting-to-Standard-LP"><a href="#Converting-to-Standard-LP" class="headerlink" title="Converting to Standard LP"></a>Converting to Standard LP</h3><h4 id="Rule-1-Unrestricted-free-variables"><a href="#Rule-1-Unrestricted-free-variables" class="headerlink" title="Rule 1: Unrestricted (free) variables"></a>Rule 1: Unrestricted (free) variables</h4><p>For any $x_i\in\bold{R}$, we can divide it into a positive component $x_i^+$ and a negative component $x_i^-$, which satisfy</p>
<script type="math/tex; mode=display">
x_i^+=
    \left\{
    \begin{aligned}
    &x_i^+,&\;\text{if}\;x_i\geq0\\
    &0,&\;\text{otherwise}
    \end{aligned}
    \right.</script><script type="math/tex; mode=display">
x_i^-=
    \left\{
    \begin{aligned}
    &0,&\;\text{if}\;x_i\geq0\\
    &x_i^-,&\;\text{otherwise}
    \end{aligned}
    \right.</script><p>Therefore, $x_i$ can be written as $x_i=x_i^++x_i^-$, in which $x_i^+,\;x_i^-\geq0$. If we have an absolute valve $|x_i|$ in the LP model, it can be displaced by $|x_i|=x_i^++x_i^-$.<br><strong>Notice</strong>: Such decomposition introduces an extra constraint: $x_i^+\times x_i^-=0$, which is important by usually ignored. This second-ordered constraint makes sure the uniqueness of the solution.</p>
<h4 id="Rule-2-Inequality-constraints"><a href="#Rule-2-Inequality-constraints" class="headerlink" title="Rule 2: Inequality constraints"></a>Rule 2: Inequality constraints</h4><p>For </p>
<script type="math/tex; mode=display">a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n\leq b_1</script><p>we introduce a slack variable $s_i$ and the original inequality constraint can be transformed to </p>
<script type="math/tex; mode=display">a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n+s_i=b_1</script><p>in which $s_i\geq0$.</p>
<p>Similarly, for </p>
<script type="math/tex; mode=display">a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n\geq b_1</script><p>we introduce an excess variable $e_i$ and the original inequality constraint can be transformed to </p>
<script type="math/tex; mode=display">a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n-e_i=b_1</script><p>in which $e_i\geq0$.</p>
<h4 id="Rule-3-Minimization-of-the-Objective-Funtion"><a href="#Rule-3-Minimization-of-the-Objective-Funtion" class="headerlink" title="Rule 3: Minimization of the Objective Funtion"></a>Rule 3: Minimization of the Objective Funtion</h4><script type="math/tex; mode=display">
\boldsymbol{Max\;c^T=-Min(-c^Tx)}</script><h3 id="Potential-Problem-caused-by-Standardizing"><a href="#Potential-Problem-caused-by-Standardizing" class="headerlink" title="Potential Problem caused by Standardizing"></a>Potential Problem caused by Standardizing</h3><ol>
<li>One quadratic constraint $x_i^+\times x_i^-=0$ is missing in the LP model</li>
<li>Dimensionality increased</li>
<li>One original solution corresponds to many new solutions</li>
<li>Since $|x|$ is a convex function while $-|x|$ is a concave function, maximize $c|x|$ can only be solved when c is negative, or the solution lies on the infinite.</li>
</ol>
<hr>
<h2 id="Lecture-3-Geometry-of-LP"><a href="#Lecture-3-Geometry-of-LP" class="headerlink" title="Lecture 3: Geometry of LP"></a>Lecture 3: Geometry of LP</h2><h3 id="Terminologies"><a href="#Terminologies" class="headerlink" title="Terminologies"></a>Terminologies</h3><h4 id="Baseline-model"><a href="#Baseline-model" class="headerlink" title="Baseline model:"></a>Baseline model:</h4><script type="math/tex; mode=display">
\begin{aligned}
  Min \;\;\bold{c^Tx} &\\
  s.t. \;\;\;\;\bold{Ax=b} &\\
  \bold{x}\geq0 &
\end{aligned}</script><h4 id="Feasible-domain"><a href="#Feasible-domain" class="headerlink" title="Feasible domain"></a>Feasible domain</h4><script type="math/tex; mode=display">
P=\{\bold{x\in R^n|Ax=b,x\geq0}\}</script><h4 id="Feasible-solution"><a href="#Feasible-solution" class="headerlink" title="Feasible solution"></a>Feasible solution</h4><p>If $\bold{x}\in P$, then <strong>x</strong> is a <em>feasible</em> <em>solution</em>.</p>
<h4 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h4><p>When $P\neq\phi$, LP is <em>consistent</em>.</p>
<h3 id="Background-knowledge"><a href="#Background-knowledge" class="headerlink" title="Background knowledge"></a>Background knowledge</h3><h4 id="Definition-of-hyperplane"><a href="#Definition-of-hyperplane" class="headerlink" title="Definition of hyperplane"></a>Definition of hyperplane</h4><p>Each equality constraint in the standard form LP is a “hyperplane” in the solution space. In the 2-D space, it is a line. In 3-D space, it is a plane.</p>
<p>For a vector $\bold{a}\in\bold{R}^n, a\neq0$ and a scaler $\beta\in\bold{R}$</p>
<script type="math/tex; mode=display">
H=\{\bold{x}\in\bold{R}^n|\bold{a}^T\bold{x}=\beta\}</script><p>is defined as a hyperplane, which divides the solution space into 3 parts, the open upper-half space $\boldsymbol{H}_u^i$ (in which $\bold{a}^T\bold{x}\gt\beta$), the hyperplane and the open lower-half space $\boldsymbol{H}_l^i$ (in which $\bold{a}^T\bold{x}&lt;\beta$). The upper-half space $\boldsymbol{H}_u=\boldsymbol{H}_u^i+\boldsymbol{H}$, similarly for $\boldsymbol{H}_l$. $\boldsymbol{H}$ is also called the bounded hyperplane of $\boldsymbol{H}_u^i$ and $\boldsymbol{H}_l^i$.</p>
<p>The vector <strong>a</strong> is the <strong><em>normal</em></strong> of the hyperplane and it points to the upper-half in the direction which increases $(in which $\bold{a}^T\bold{x}$ fastest. </p>
<h4 id="Properties-of-hyperplanes"><a href="#Properties-of-hyperplanes" class="headerlink" title="Properties of hyperplanes"></a>Properties of hyperplanes</h4><p>Property 1: The normal vector <strong>a</strong> is <em>orthogonal to</em> all vectors in the hyperplane <strong>H</strong>.</p>
<p>Property 2: The normal vector is <em>directed</em> <em>toward</em> the upper half space.</p>
<h4 id="Properties-of-feasible-solution-set"><a href="#Properties-of-feasible-solution-set" class="headerlink" title="Properties of feasible solution set"></a>Properties of feasible solution set</h4><p>Property 3: The feasible domain of a standard form LP</p>
<script type="math/tex; mode=display">
P=\{\bold{x\in R^n|Ax=b,x\geq0}\}</script><p>is a polyhedral set.</p>
<p>A polyhedral set or polyhedron is a set formed by the intersection of a <strong>finite</strong> number of closed half spaces. If it is nonempty or bounded, it is a polytope.</p>
<h4 id="Properties-of-optimal-solutions"><a href="#Properties-of-optimal-solutions" class="headerlink" title="Properties of optimal solutions"></a>Properties of optimal solutions</h4><p>Property 4:if $P\neq0$ and $\exist\beta\in\bold{R}$ such that</p>
<script type="math/tex; mode=display">
P\subset H_L:=\{\bold{x\in R^n|-c^Tx\leq\beta}\}</script><p>then $\min\limits_{x\in P}\bold{c^Tx\geq-\beta}$.</p>
<p>Moreover, if $\bold{x^<em>}\in P\cap H$, then $\bold{x^</em>}\in P^*$</p>
<h3 id="Graphic-method"><a href="#Graphic-method" class="headerlink" title="Graphic method"></a>Graphic method</h3><h4 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1:"></a>Step 1:</h4><p>Draw the feasible domain $P$</p>
<h4 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2:"></a>Step 2:</h4><p>Use $-\bold{c}$ as normal vector at each vertex to see if $P\subset H_L:={\bold{x\in R^n|-c^Tx\leq\beta}}$ for some $\beta\in \bold{R}$. If yes, then we found the optimal solution.</p>
<ul>
<li>Advantage: Intuitional / Geometrically simple</li>
<li>Disadvantage: Impractical for large LP problems / Algebraically difficult</li>
</ul>
<h3 id="Fundamental-theorem-of-LP"><a href="#Fundamental-theorem-of-LP" class="headerlink" title="Fundamental theorem of LP"></a>Fundamental theorem of LP</h3><h4 id="Background-knowledge-1"><a href="#Background-knowledge-1" class="headerlink" title="Background knowledge"></a>Background knowledge</h4><p>Definition: Let $\bold{x^1,x^2,\dotsb,x^p\in R^n,\; \lambda_1,\lambda_2,\dotsb,\lambda_p\in R^n}$, for </p>
<script type="math/tex; mode=display">
\bold{x}=\sum_{i=1}^{p}\bold{\lambda_ix^i}</script><p>we say <strong>x</strong> is a <em>linear</em> <em>combination</em> of ${\bold{x^1,\dotsb,x^p}}$.</p>
<ul>
<li>If $\sum_{i=1}^{p}\lambda_i=1$, w say <strong>x</strong> is an affine combination of ${\bold{x^1,\dotsb,x^p}}$.<br>If the affine combination of any two points of S falls in S, then S is an <em>affine</em> <em>set</em>.</li>
<li>If $\lambda_i\geq0$, we say <strong>x</strong> is a conic combination of ${\bold{x^1,\dotsb,x^p}}$.<br>If $\lambda\bold{x}\in S$ for all $\bold{x}\in S$ and $\lambda\geq0$, then S is a <em>cone</em>.</li>
<li>If $\sum_{i=1}^{p}\lambda_i=1,\;\lambda_i\geq0$, w say <strong>x</strong> is an convex combination of ${\bold{x^1,\dotsb,x^p}}$.<br>If the convex combination of ant two points of S falls in S, then S is a <em>convex</em> <em>set</em>.</li>
</ul>
<h3 id="The-geometric-meaning-of-the-feasible-domain"><a href="#The-geometric-meaning-of-the-feasible-domain" class="headerlink" title="The geometric meaning of the feasible domain"></a>The geometric meaning of the feasible domain</h3><script type="math/tex; mode=display">
P=\{\bold{x\in R^n|Ax=b,x\geq0}\}</script><ol>
<li>P is a <em>polyhedral</em> set.</li>
<li>P is a <em>convex</em> set</li>
<li>P is the <em>intersection</em> of <strong>m</strong> <em>hyperplanes</em> and the <em>cone</em> of the first orthant.</li>
</ol>
<p>Seeing $\bold{Ax=b}$ in the column picture (see MIT 1806), if the vector <strong>b</strong> falls in the cone generated by the columns of constraint matrix <strong>A</strong>.</p>
<h4 id="Interior-and-boundary-points"><a href="#Interior-and-boundary-points" class="headerlink" title="Interior and boundary points"></a>Interior and boundary points</h4><p>Definition: Given a set $S\in\bold{R^n}$, a point $\bold{x\in S}$ is an interior point of S if</p>
<script type="math/tex; mode=display">
\exist\;\epsilon>0\;\text{such that the ball}\;\bold{B=\{y\in R^n|\;||x-y||\leq\epsilon\}\subset S}</script><p>called $\bold{x\in}int(S)$</p>
<p>Otherwise, <strong>x</strong> is a boundary point of S, we say $\bold{x}\in bdry(S)$.</p>
<h4 id="How-to-define-a-convex-set-S"><a href="#How-to-define-a-convex-set-S" class="headerlink" title="How to define a convex set S"></a>How to define a convex set <strong>S</strong></h4><ul>
<li>For all interior point, the segment between any two interior points falls in the convex set <strong>S</strong>.</li>
<li>For $\forall$ boundary point <strong>x</strong>, $\exist$ a hyperplane <strong>H</strong> that $\bold{x\in S}$ and <strong>S</strong> falls in $\bold{H_L}\;\text{or}\;\bold{H_U}$.</li>
<li>For $\forall$ outside point <strong>x</strong>, $\exist$ a hyperplane <strong>H</strong> that <strong>x</strong> lies in $\bold{H_L}$ and <strong>S</strong> falls in the $\bold{H_U}$, or vise versa.</li>
</ul>
<h4 id="Difference-among-boundary-points"><a href="#Difference-among-boundary-points" class="headerlink" title="Difference among boundary points"></a>Difference among boundary points</h4><p><strong>x</strong> is defined as an extreme point of a convex set S if <strong>x</strong> cannot be expressed as a <em>convex</em> <em>combination</em> of other points in S.</p>
<p>The <strong>extreme</strong> <strong>points</strong> are not exactly the same as the <strong>vertices</strong> according to their definition. But for the feasible domain P of an LP, it vertices are the extreme points.</p>
<h4 id="Finding-extreme-points"><a href="#Finding-extreme-points" class="headerlink" title="Finding extreme points"></a>Finding extreme points</h4><p>Theorem: A point $\bold{x\in}P={\bold{x\in R^n|Ax=b,x\geq0}}$ is an extreme point of P <strong><em>if and only if</em></strong> the columns of A corresponding to the positive components of <strong>x</strong> are linearly independent.</p>
<p>Proof:<br>Without loss of generality, we may assume that the first <em>p</em> components of <strong>x</strong> are positive and the rest are zero, i.e.,</p>
<script type="math/tex; mode=display">
\bold{x=\left(\begin{array}{c}
  \bar{x}\\0
\end{array}\right)}
\;\text{where}\;
\bold{\bar{x}}=\left(\begin{array}{c}
  x_1\\\vdots\\x_p
\end{array}\right)\;>0</script><p>also denote the first <em>p</em> column of <strong>A</strong> by $\bold{\bar{A}}$ then $\bold{Ax=\bar{A}\bar{x}=b}$.</p>
<p>Suppose that the columns of $\bold{\bar{A}}$ are not linearly independent, then $\bold{\exist\;\bar{w}\neq0}$ such that $\bold{\bar{A}\bar{w}=0}$.</p>
<p>Notice that for $\epsilon$ is small enough</p>
<script type="math/tex; mode=display">
\bold{\bar{x}\plusmn\epsilon\bar{w}\;\text{and}\;\bar{A}(\bar{x}\plusmn\epsilon\bar{w})=\bar{A}\bar{x}=b}</script><p>Hence, </p>
<script type="math/tex; mode=display">
\bold{y_1=\left(\begin{array}{c}
  \bar{x}+\epsilon\bar{w}\\0
\end{array}\right)\in \textit{P}}</script><script type="math/tex; mode=display">
\bold{y_2=\left(\begin{array}{c}
  \bar{x}-\epsilon\bar{w}\\0
\end{array}\right)\in \textit{P}}</script><p>and $\bold{x}=\frac{1}{2}y_1+\frac{1}{2}y_2$, i.e. <strong>x</strong> cannot be a vertex (extreme point) of P.</p>
<p>Thus, <strong>x</strong> is an extreme point when the columns of $\bold{\bar{A}}$ are linearly indeoendent.</p>
<p>Suppose that <strong>x</strong> is not an extreme point, then $\bold{x=\lambda y_1+\lambda y_2}$ for some $\bold{y_1,\;y_2\in P,\; y_1\neq y_2\;\text{and}\;}0&lt;\lambda&lt;1$.</p>
<p>Since $\bold{y_1\geq0,\;y_2\geq0}$ and $0&lt;\lambda&lt;1$, the last $n-p$ components of $\bold{y_1}$ must be zero, i.e.</p>
<script type="math/tex; mode=display">
\bold{y_1=\left(\begin{array}{c}
  \bar{\bold{y}}\\0
\end{array}\right)}</script><p>Now </p>
<script type="math/tex; mode=display">
\bold{x-y_1=\left(\begin{array}{c}
  \bar{\bold{x}}-\bar{\bold{y}}_1\\0
\end{array}\right)\neq0}</script><p>and $\bold{A(x-\bold{\bar{y}}_1)=Ax-A\bar{\bold{y}}_1=b-b=0}$, which indicates that the columns of A are linearly dependent.</p>
<p>Thus, the theorem is proofed.</p>
<h4 id="Managing-extreme-points-algebraically"><a href="#Managing-extreme-points-algebraically" class="headerlink" title="Managing extreme points algebraically"></a>Managing extreme points algebraically</h4><p><strong>Full rank matrix</strong>: Let A be an <em>m</em> by <em>n</em> matrix with $m\leq n$, we say A has full rank (since $m\leq n$, full row rank) if A has <em>m</em> linearly independent columns.</p>
<p>Rearrange x as</p>
<script type="math/tex; mode=display">
\bold{
  x=\left(\begin{array}{c}
    \bold{x_B}\\\bold{x_N}
  \end{array}\right)
  \begin{array}{c}
    - & \text{basic variabls}\\
    - & \text{non-basic variables}
  \end{array}
}\;\;\;\;
\begin{aligned}
  \bold{A}= (&\bold{B}&|\text{\;\;\;\;}&\bold{N}&)\\
  &\uparrow&\text{\;\;\;\;}& \uparrow&\\
  &\text{basis}&\text{\;\;\;\;}&\text{non-basis}&
\end{aligned}</script><ul>
<li>If we set $\bold{x_N}=0$ and solve $\bold{x_B}$ for $\bold{Ax=Bx_B=b}$ then <strong>x</strong> is a $\underline{basic\ solution}$ (bs).</li>
<li>Furthermore, if $\bold{x_B}\geq0$, then <strong>x</strong> is a $\underline{basic\ feasible\ solution}$.</li>
</ul>
<p>We can see, when A does not have full rank, then  either</p>
<ul>
<li>Ax = b has $\underline{no\ solution}$ and hence $P=0$, or</li>
<li>some constraints are redundant (which can be avoided by preprocessing matrix A).</li>
</ul>
<p>Thus,</p>
<ol>
<li>A point <strong>x</strong> in P is an <strong>extreme</strong> <strong>point</strong> of P if and only if <strong>x</strong> is a <em>basic</em> <em>feasible</em> <em>solution</em> corresponding to some basis B.</li>
<li>The polyhedron P has only a <strong>finite</strong> <strong>number</strong> of extreme points (less than $C_m^n$).</li>
</ol>
<h4 id="What-do-extreme-points-bring-us"><a href="#What-do-extreme-points-bring-us" class="headerlink" title="What do extreme points bring us?"></a>What do extreme points bring us?</h4><p>When $P={\bold{x\in R^n|Ax=b,x\geq0}}$ is a nonempty polytope, then any point in P can be represented as a <strong>convex</strong> <strong>combination</strong> of the extreme points of P.</p>
<p>If P is unbounded, there exists an <strong>extremal</strong> <strong>direction</strong>.</p>
<ul>
<li>Definition: A vector $\bold{d(\neq0)\in R^n}$ is an <strong>extremal</strong> <strong>direction</strong> of P, if ${\bold{x\in R^n|x=x_0+\lambda d,\ \lambda\geq0}\subset }P$ for all $\bold{x_0}\in P$.</li>
<li><strong>d</strong> satisfies $\bold{Ad=0}$ and $\bold{d\geq 0}$.</li>
</ul>
<h4 id="Resolution-theorem"><a href="#Resolution-theorem" class="headerlink" title="Resolution theorem"></a>Resolution theorem</h4><p>Let $\bold{V = {v_i\in R^n|}i\in I}$ be a set of extreme points of P, then for $\forall x \in P$</p>
<script type="math/tex; mode=display">
\bold{x}=\sum\limits_{i\in I} \lambda_iv_i+\bold{d}</script><p>where</p>
<script type="math/tex; mode=display">
\sum\limits_{i\in I}\lambda_i=1,\ \lambda_i\geq0,\ \forall i\in I.</script><p>and either $\bold{d=0}$ or <strong>d</strong> is an extremal direction of <strong><em>P</em></strong></p>
<h4 id="Fundamental-theorem-of-LP-1"><a href="#Fundamental-theorem-of-LP-1" class="headerlink" title="Fundamental theorem of LP"></a>Fundamental theorem of LP</h4><p>For a standard form LP, if its feasible domain P is nonempty, then the optimal objective value of $\bold{z=c^Tx}\ over\ P$ is either <strong><em>unbounded</em></strong> below, or it is attained <strong><em>at (at least) an extreme point</em></strong> of P.</p>
<h2 id="Lecture-4-Simplex-Method"><a href="#Lecture-4-Simplex-Method" class="headerlink" title="Lecture 4: Simplex Method"></a>Lecture 4: Simplex Method</h2><h3 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea:"></a>Basic Idea:</h3><ul>
<li><p>Phase 1:</p>
<ul>
<li>Step 1 (Starting): Find an initial extreme point (ep) or declare P in null.</li>
</ul>
</li>
<li><p>Phase 2:</p>
<ul>
<li>Step 2 (Checking optimality): if the current eo is optimal, <strong>STOP</strong>.</li>
<li>Step 3 (Pivoting): Move to a better ep, then return to Step 2.</li>
</ul>
</li>
</ul>
<p>If we do not repeat using the same extreme point, then the algorithm will always terminates in finite number of iterations.</p>
<p>But how to efficiently generate better extreme points?</p>
<p>In the algebra term, we just need to use <strong>basic</strong> <strong>feasible</strong> <strong>solution</strong> to replace <strong>extreme</strong> <strong>point</strong> above.</p>
<p>If there exists at least one basic variable becoming <strong>zero</strong>, the extreme point may correspond to more than one basic feasible solution, in this case we say the bfs is a degenerate one.</p>
<h3 id="Nondegeneracy"><a href="#Nondegeneracy" class="headerlink" title="Nondegeneracy"></a>Nondegeneracy</h3><h4 id="Property-1"><a href="#Property-1" class="headerlink" title="Property 1:"></a>Property 1:</h4><p>If a bfs <strong>x</strong> is nondegenerate, then <strong>x</strong> is <em>uniquely</em> <em>determined</em> by <em>n</em> hyperplanes.</p>
<p>Let $\bold{M=}\left[\begin{array}{cc}<br>  \bold{B} &amp; \bold{N}\<br>  \bold0 &amp; \bold{I}<br>\end{array}\right]$, <strong>M</strong> is a nonsingular matrix.</p>
<p><strong>x</strong> is uniquely determined by <em>n</em> linearly independent hyperplanes since</p>
<script type="math/tex; mode=display">
\bold{Mx}=\left[\begin{array}{cc}
  \bold{B} & \bold{N}\\
  \bold{0} & \bold{I}
\end{array}\right]\left[\begin{array}{c}
  \bold{x_B}\\ \bold{x_N}
\end{array}\right]=\left[\begin{array}{c}
  \bold{b}\\ \bold{0}
\end{array}\right]</script><script type="math/tex; mode=display">
\bold{x}=\left[\begin{array}{c}
  \bold{x_B}\\\bold{x_N}
\end{array}\right]=\bold{M^{-1}}\left[\begin{array}{c}
  \bold{b}\\ \bold{0}
\end{array}\right]</script><p>in which,</p>
<script type="math/tex; mode=display">
\bold{M^{-1}}=\left[\begin{array}{cc}
  \bold{B^{-1}} & \bold{-B^{-1}N}\\
  \bold{0} & \bold{I}
\end{array}\right]</script><p>We call $\bold{M^{-1}}$ (or <strong>M</strong>) the <strong><em>fundamental</em></strong> <strong><em>matrix</em></strong> of LP.</p>
<h4 id="Property-2"><a href="#Property-2" class="headerlink" title="Property 2:"></a>Property 2:</h4><p>If a bfs <strong>x</strong> is degenerate, then <strong>x</strong> is overdetermined by more than <em>n</em> hyperplanes.</p>
<p>Other than <em>n</em> hyperplanes determined by non-basic variables, there exists at least one basic variable that $x_i=0$, which indicates an extra hyperplane.</p>
<h3 id="Simplex-method-under-nondegeneracy"><a href="#Simplex-method-under-nondegeneracy" class="headerlink" title="Simplex method under nondegeneracy"></a>Simplex method under nondegeneracy</h3><h4 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea:"></a>Basic idea:</h4><p>Instead of considering all bfs at the same time, wo just consider some neighboring bfs, moving from one bfs to another with a <em>simple</em> <em>pivoting</em> scheme.</p>
<h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>Two basic feasible solution are adjacent if they have $\textit{m-1}$ <strong><em>basic</em></strong> <strong><em>variables</em></strong> in common.</p>
<p>Each bfs has $\textit{m-n}$ adjacent neighbors, which can be reached by increasing one non basic variable from zero to positive and decrease one basic variable to 0, called <strong>pivoting</strong>.</p>
<hr>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/About"> About</a></li><li class="nav_item"><a class="nav-page" href="/Research"> Research</a></li><li class="nav_item"><a class="nav-page" href="/Project"> Project</a></li><li class="nav_item"><a class="nav-page" href="/Notes"> Notes</a></li><li class="nav_item"><a class="nav-page" href="/Album"> Album</a></li><li class="nav_item"><a class="nav-page" href="/Feiyue"> Feiyue for ECE</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2023 by Hongyi Li</div><div class="theme-info">Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener">Hexo</a> & <a href="https://github.com/PhosphorW/hexo-theme-academia" target="_blank" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>